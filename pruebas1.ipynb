{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91d5f53c",
   "metadata": {},
   "source": [
    "Importar librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4973b6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web scraping\n",
    "#from langchain_community.document_loaders import WebBaseLoader\n",
    "#from bs4 import BeautifulSoup\n",
    "\n",
    "import requests\n",
    "#Embeddings\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "# Prompts\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "# doc loaders\n",
    "from langchain_community.document_loaders import DirectoryLoader, PyPDFLoader, TextLoader, Docx2txtLoader\n",
    "# ChromaDB\n",
    "from langchain_community.vectorstores import Chroma\n",
    "# text splitter\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "# runnable\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "# Tools\n",
    "from langchain.tools import tool\n",
    "# LLM ollama\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.agents import create_agent\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, ToolMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ebf7ed",
   "metadata": {},
   "source": [
    "# Preparar documentos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f796fc2",
   "metadata": {},
   "source": [
    "## Cargar docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b14dcd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar todos los PDFs de la carpeta \"Contratos\" con PyPDFLoader\n",
    "loader = DirectoryLoader(\n",
    "    path=\"./Contratos\",\n",
    "    glob=\"**/*.pdf\",        # Cargar solo archivos PDF\n",
    "    loader_cls=PyPDFLoader  # Cargar solo archivos PDF\n",
    ")\n",
    "\n",
    "documentos = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba56bb8",
   "metadata": {},
   "source": [
    "## Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc53933f",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,       # caracteres por chunk\n",
    "    chunk_overlap=50      # solapamiento entre chunks (mantiene contexto)\n",
    ")\n",
    "\n",
    "chunks = splitter.split_documents(documentos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee65ae76",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19bb062b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OllamaEmbeddings(model=\"llama3.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb05f5c3",
   "metadata": {},
   "source": [
    "# Chroma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22af56f8",
   "metadata": {},
   "source": [
    "## Crear/Cargar base de datos vectorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6466dc17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ame Contreras\\AppData\\Local\\Temp\\ipykernel_23204\\337347211.py:9: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the `langchain-chroma package and should be used instead. To use it run `pip install -U `langchain-chroma` and import as `from `langchain_chroma import Chroma``.\n",
      "  vectorstore = Chroma(\n"
     ]
    }
   ],
   "source": [
    "Crear = False\n",
    "if Crear: #Crear la base de datos (solo la primera vez)\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents=chunks,\n",
    "        embedding=embeddings,\n",
    "        persist_directory=\"./chroma_db\"\n",
    "    )\n",
    "else:     # Cargar la base de datos ya creada\n",
    "    vectorstore = Chroma(\n",
    "        persist_directory=\"./chroma_db\",\n",
    "        embedding_function=embeddings\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b4f01d",
   "metadata": {},
   "source": [
    "### Agregar nuevos documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c9e96fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorstore.add_documents(nuevos_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad9f2ca",
   "metadata": {},
   "source": [
    "# RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c851f246",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd5e64a",
   "metadata": {},
   "source": [
    "# LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57cd251",
   "metadata": {},
   "source": [
    "## Agente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c4b992",
   "metadata": {},
   "source": [
    "###  LLM compartido \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07b091cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(model=\"llama3.2\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f50eb37",
   "metadata": {},
   "source": [
    "###  Chains internas + tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8371b595",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(d.page_content for d in docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28881249",
   "metadata": {},
   "source": [
    "#### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1aa51ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tem_chat_analysis = \"\"\" \n",
    "Eres un asistente especializado en contratos de arrendamiento. \n",
    "Tu función es responder preguntas, proporcionar resúmenes y realizar análisis generales sobre los contratos de arrendamiento.\n",
    "Utiliza la información disponible en los documentos para ofrecer respuestas precisas y detalladas a las consultas de los usuarios.\n",
    "\"\"\"\n",
    "\n",
    "chain_analysis = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | ChatPromptTemplate.from_template(tem_chat_analysis + \"\"\"\n",
    "\n",
    "Contexto de los documentos:\n",
    "{context}\n",
    "\n",
    "Pregunta o solicitud: {question}\n",
    "\"\"\")\n",
    "    | llm\n",
    ")\n",
    "\n",
    "@tool\n",
    "def chat_analysis(query: str) -> str:\n",
    "    \"\"\"Analiza, resume o responde preguntas generales sobre contratos de arrendamiento.\"\"\"\n",
    "    result = chain_analysis.invoke(query)\n",
    "    return result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc7a70a",
   "metadata": {},
   "source": [
    "#### Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99148450",
   "metadata": {},
   "outputs": [],
   "source": [
    "tem_filter_search  = \"\"\"\n",
    "Eres un asistente especializado en buscar y filtrar contratos de arrendamiento.\n",
    "Tu función es ayudar a los usuarios a encontrar contratos específicos basados en criterios como fecha, tipo de contrato, partes involucradas o ubicación.\n",
    "\"\"\"\n",
    "\n",
    "chain_filter = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | ChatPromptTemplate.from_template(tem_filter_search + \"\"\"\n",
    "\n",
    "Contratos encontrados:\n",
    "{context}\n",
    "\n",
    "Búsqueda solicitada: {question}\n",
    "\"\"\")\n",
    "    | llm\n",
    ")\n",
    "\n",
    "@tool\n",
    "def filter_search(query: str, tipo: str = None, año: int = None) -> str:\n",
    "    \"\"\"Busca contratos específicos por filtros como tipo, año o arrendador.\"\"\"\n",
    "    result = chain_filter.invoke(query)\n",
    "    return result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f2d4be",
   "metadata": {},
   "source": [
    "#### Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5741d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tem_generation_tool = \"\"\"\n",
    "Eres un asistente especializado en crear o sugerir cláusulas, generar borradores o redactar términos de contratos de arrendamiento.\n",
    "Tu función es ayudar a los usuarios a generar contenido relacionado con contratos de arrendamiento, ya sea creando nuevas cláusulas, sugiriendo redacciones o generando borradores completos.\n",
    "\"\"\"\n",
    "\n",
    "chain_generation = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | ChatPromptTemplate.from_template(tem_generation_tool + \"\"\"\n",
    "\n",
    "Cláusulas de referencia encontradas:\n",
    "{context}\n",
    "\n",
    "Solicitud de generación: {question}\n",
    "\n",
    "AVISO: Las sugerencias generadas no constituyen asesoría jurídica.\n",
    "\"\"\")\n",
    "    | llm\n",
    ")\n",
    "\n",
    "@tool\n",
    "def generation_tool(tipo_clausula: str, condiciones: str) -> str:\n",
    "    \"\"\"Genera o sugiere cláusulas para contratos de arrendamiento.\"\"\"\n",
    "    query = f\"{tipo_clausula}: {condiciones}\"\n",
    "    result = chain_generation.invoke(query)\n",
    "    return result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878928b8",
   "metadata": {},
   "source": [
    "#### Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8094c695",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [chat_analysis, filter_search, generation_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecc844e",
   "metadata": {},
   "source": [
    "### Router prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04b609a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tem_PagPrincipal = \"\"\"\n",
    "Eres un asistente especializado en contratos de arrendamiento. \n",
    "Tienes acceso a estas herramientas: \n",
    "    chat_analysis:      para consultas, resúmenes y análisis generales; \n",
    "    filter_search:      cuando el usuario quiere buscar contratos por criterios específicos como fecha, tipo, partes o ubicación; \n",
    "    generation_tool:    cuando el usuario quiere crear o sugerir cláusulas, generar borradores o redactar términos. \n",
    "Determina cuál usar según la solicitud y extrae los parámetros relevantes.\n",
    "\"\"\"\n",
    "\n",
    "prompt_agente = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", tem_PagPrincipal),\n",
    "    MessagesPlaceholder(\"chat_history\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    MessagesPlaceholder(\"agent_scratchpad\"),\n",
    "])\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=tools,\n",
    "    system_prompt=tem_PagPrincipal,\n",
    "    debug=True  # equivalente a verbose=True\n",
    ")\n",
    "#executor = AgentExecutor(agent=agent, tools=tools, verbose=True\n",
    "#,return_intermediate_steps=True) # para ver qué tools usó"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87559af4",
   "metadata": {},
   "source": [
    "## Manejo de entradas y salidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c779f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Manejo de historial ──────────────────────────────────────────────────────\n",
    "chat_history = []\n",
    "\n",
    "def chat(user_input: str):\n",
    "    response = agent.invoke({\n",
    "        \"messages\": [\n",
    "            *chat_history,\n",
    "            {\"role\": \"user\", \"content\": user_input}\n",
    "        ]\n",
    "    })\n",
    "\n",
    "    all_messages = response[\"messages\"]\n",
    "    final_output = all_messages[-1].content\n",
    "\n",
    "    # Actualizar historial (solo human + AI final, sin tool messages)\n",
    "    chat_history.append(HumanMessage(content=user_input))\n",
    "    chat_history.append(AIMessage(content=final_output))\n",
    "\n",
    "    # Extraer intermediate steps (tool calls)\n",
    "    intermediate_steps = []\n",
    "    for msg in all_messages:\n",
    "        if isinstance(msg, AIMessage) and msg.tool_calls:\n",
    "            for tool_call in msg.tool_calls:\n",
    "                # Buscar el ToolMessage correspondiente\n",
    "                tool_result = next(\n",
    "                    (m.content for m in all_messages if isinstance(m, ToolMessage) \n",
    "                    and m.tool_call_id == tool_call[\"id\"]),\n",
    "                    None\n",
    "                )\n",
    "                intermediate_steps.append({\n",
    "                    \"tool\": tool_call[\"name\"],\n",
    "                    \"params\": tool_call[\"args\"],\n",
    "                    \"result\": tool_result\n",
    "                })\n",
    "\n",
    "    return {\"output\": final_output, \"intermediate_steps\": intermediate_steps}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8a1efa",
   "metadata": {},
   "source": [
    "# Pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fd9614",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchainENV (3.12.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
